# Mesh Convolution 
This repository contains the code (in PyTorch) for the paper "Mesh Convolution Using a Learned Kernel Basis".

## Contents
1. [Introduction](#introduction)
2. [Usage](#usage)
3. [Citation](#citation)

## Introduction
Here we provide the implementation of convolution,transpose convolution, pooling, unpooling, and residual neural network layers for mesh or graph data with an unchanged topology. We demonstrate the usage by the example of training an auto-encoder for the [D-FAUST dataset](http://dfaust.is.tue.mpg.de/). If you read through this document, it won't be complicated to build up other types of networks with our code.

## Usage
### 1. Overview:
The files are organized by three folders: code, data and train. 
**code** contains two programs. *GraphSampling* is used to down and up-sample the input graph and create the *connection matrices* at each step which will be later used by *GraphAE* to build up the network layers. 
**data** contains the template mesh files and the processed feature data.
**Train** stores the *connection matrices* generated by *GraphSampling*, the experiment configuration files and the training results.

### 2. Environment
For compiling and running the C++ project in *GraphSampling*, you need to install cmake, ZLIB and opencv.

For running the python code in GraphAE, I recommend to use anaconda virtual environment with python3.6, numpy, pytorch0.4.1 or higher version such as pytorch1.3, plyfile, json, configparser, tensorboardX, matplotlib, transforms3d, opencv-python. For visualization, you will need freeglut and pythonOpenGL.

### 3. Data Preparation
#### Step One: 
Download registrations_f.hdf5 and registrations_m.hdf5 from [D-FAUST](http://dfaust.is.tue.mpg.de/) to data/DFAUST/ and use code/GraphAE/graphAE_datamaker_DFAUST.py to generate numpy arrays, train.npy, eval.npy and test.npy for training, validation and testing, with dimension pc_num*point_num*channel (pc for a model instance, point for vertex, channel for features). Please write to me for getting the exact training and testing data we used in the paper.

#### Step Two: 
Pick up an arbitray mesh in the dataset as the template mesh and create:
1. template.obj. It will be used by *GraphSampling*. If you want to manually assign some center vertices, set their color to be red (1.0, 0, 0) using the paint tool in MeshLab as the example template.obj in data/DFAUST.

2. template.ply. It will be used by *GraphAE* for saving temporate result in ply.

We have put the example templated.obj and template.ply files in data/DFAUST. 

### 2. GraphSampling
This code will load template.obj, compute the down and up-sampling graphs and write the *connection matrices* for each layer into .npy files. Please refer to Section 3.1, 3.4 and Appendix A.2 in the paper and the comments in the code for understanding the algorithms.

For compiling and running the code, go to "code/GraphSampling", open the terminal, run
```
cmake .
make
./GraphSampling
```

#### *Connection matrix* 
This matrix defines the connection between the input graph and the output graph. has the dimension of out_point_num*(1+max_neighbor_num*2). Each row i contains the indices and distance of the vertices in the input graph that are connected with the vertex i in the output graph, padded by virtual vertices. The format is 
{N, {id0, dist0}, {id1, dist1}, ..., {idN, distN}, {in_point_num, -1}*max_neighbor_num}


